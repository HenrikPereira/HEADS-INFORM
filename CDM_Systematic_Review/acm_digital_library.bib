@article{10.1145/3514500,
author = {Dang, Trung Kien and Lan, Xiang and Weng, Jianshu and Feng, Mengling},
title = {Federated Learning for Electronic Health Records},
year = {2022},
issue_date = {October 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {13},
number = {5},
issn = {2157-6904},
url = {https://doi.org/10.1145/3514500},
doi = {10.1145/3514500},
abstract = {In data-driven medical research, multi-center studies have long been preferred over single-center ones due to a single institute sometimes not having enough data to obtain sufficient statistical power for certain hypothesis testings as well as predictive and subgroup studies. The wide adoption of electronic health records (EHRs) has made multi-institutional collaboration much more feasible. However, concerns over infrastructures, regulations, privacy, and data standardization present a challenge to data sharing across healthcare institutions. Federated Learning (FL), which allows multiple sites to collaboratively train a global model without directly sharing data, has become a promising paradigm to break the data isolation. In this study, we surveyed existing works on FL applications in EHRs and evaluated the performance of current state-of-the-art FL algorithms on two EHR machine learning tasks of significant clinical importance on a real world multi-center EHR dataset.},
journal = {ACM Trans. Intell. Syst. Technol.},
month = jun,
articleno = {72},
numpages = {17},
keywords = {neural networks, healthcare, electronic health records, Federated learning}
}

@inproceedings{10.1145/3368555.3384459,
author = {Zhang, Wei and Kuang, Zhaobin and Peissig, Peggy and Page, David},
title = {Adverse drug reaction discovery from electronic health records with deep neural networks},
year = {2020},
isbn = {9781450370462},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3368555.3384459},
doi = {10.1145/3368555.3384459},
abstract = {Adverse drug reactions (ADRs) are detrimental and unexpected clinical incidents caused by drug intake. The increasing availability of massive quantities of longitudinal event data such as electronic health records (EHRs) has redefined ADR discovery as a big data analytics problem, where data-hungry deep neural networks are especially suitable because of the abundance of the data. To this end, we introduce neural self-controlled case series (NSCCS), a deep learning framework for ADR discovery from EHRs. NSCCS rigorously follows a self-controlled case series design to adjust implicitly and efficiently for individual heterogeneity. In this way, NSCCS is robust to time-invariant confounding issues and thus more capable of identifying associations that reflect the underlying mechanism between various types of drugs and adverse conditions. We apply NSCCS to a large-scale real-world EHR dataset and empirically demonstrate its superior performance with comprehensive experiments on a benchmark ADR discovery task.},
booktitle = {Proceedings of the ACM Conference on Health, Inference, and Learning},
pages = {30–39},
numpages = {10},
keywords = {Self-Controlled Case Series, Electronic Health Records, Deep Neural Networks, Adverse Drug Reaction Discovery},
location = {Toronto, Ontario, Canada},
series = {CHIL '20}
}

@inproceedings{10.1145/3555776.3577685,
author = {Tahabi, Fattah Muhammad and Storey, Susan and Luo, Xiao},
title = {SymptomGraph: Identifying Symptom Clusters from Narrative Clinical Notes using Graph Clustering},
year = {2023},
isbn = {9781450395175},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3555776.3577685},
doi = {10.1145/3555776.3577685},
abstract = {Patients with cancer or other chronic diseases often experience different symptoms before or after treatments. The symptoms could be physical, gastrointestinal, psychological, or cognitive (memory loss), or other types. Previous research focuses on understanding the individual symptoms or symptom correlations by collecting data through symptom surveys and using traditional statistical methods to analyze the symptoms, such as principal component analysis or factor analysis. This research proposes a computational system, SymptomGraph, to identify the symptom clusters in the narrative text of written clinical notes in electronic health records (EHR). SymptomGraph is developed to use a set of natural language processing (NLP) and artificial intelligence (AI) methods to first extract the clinician-documented symptoms from clinical notes. Then, a semantic symptom expression clustering method is used to discover a set of typical symptoms. A symptom graph is built based on the co-occurrences of the symptoms. Finally, a graph clustering algorithm is developed to discover the symptom clusters. Although SymptomGraph is applied to the narrative clinical notes, it can be adapted to analyze symptom survey data. We applied Symptom-Graph on a colorectal cancer patient with and without diabetes (Type 2) data set to detect the patient symptom clusters one year after the chemotherapy. Our results show that SymptomGraph can identify the typical symptom clusters of colorectal cancer patients' post-chemotherapy. The results also show that colorectal cancer patients with diabetes often show more symptoms of peripheral neuropathy, younger patients have mental dysfunctions of alcohol or tobacco abuse, and patients at later cancer stages show more memory loss symptoms. Our system can be generalized to extract and analyze symptom clusters of other chronic diseases or acute diseases like COVID-19.},
booktitle = {Proceedings of the 38th ACM/SIGAPP Symposium on Applied Computing},
pages = {518–527},
numpages = {10},
keywords = {electronic health records, graph clustering, clinical notes, graph neural networks, symptom clusters},
location = {Tallinn, Estonia},
series = {SAC '23}
}

@inproceedings{10.1145/3472813.3473206,
author = {Prosperi, Mattia and Ghosh, Shantanu and Chen, Zhaoyi and Salemi, Marco and Lyu, Tianchen and Zhao, Jinying and Bian, Jiang},
title = {Causal AI with Real World Data: Do Statins Protect from Alzheimer's Disease Onset?},
year = {2021},
isbn = {9781450389846},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3472813.3473206},
doi = {10.1145/3472813.3473206},
abstract = {Causal artificial intelligence aims at developing bias-robust models that can be used to intervene on, rather than just be predictive, of risks or outcomes. However, learning interventional models from observational data, including electronic health records (EHR), is challenging due to inherent bias, e.g., protopathic, confounding, collider. When estimating the effects of treatment interventions, classical approaches like propensity score matching are often used, but they pose limitations with large feature sets, nonlinear/nonparallel treatment group assignments, and collider bias. In this work, we used data from a large EHR consortium –OneFlorida– and evaluated causal statistical/machine learning methods for determining the effect of statin treatment on the risk of Alzheimer's disease, a debated clinical research question. We introduced a combination of directed acyclic graph (DAG) learning and comparison with expert's design, with calculation of the generalized adjustment criterion (GAC), to find an optimal set of covariates for estimation of treatment effects –ameliorating collider bias. The DAG/CAC approach was assessed together with traditional propensity score matching, inverse probability weighting, virtual-twin/counterfactual random forests, and deep counterfactual networks. We showed large heterogeneity in effect estimates upon different model configurations. Our results did not exclude a protective effect of statins, where the DAG/GAC point estimate aligned with the maximum credibility estimate, although the 95% credibility interval included a null effect, warranting further studies and replication.},
booktitle = {Proceedings of the 5th International Conference on Medical and Health Informatics},
pages = {296–303},
numpages = {8},
keywords = {treatment effect, machine learning, generalized adjustment criterion, electronic medical records, directed acyclic graph, biomedical informatics, Causal artificial intelligence, Bayesian network},
location = {Kyoto, Japan},
series = {ICMHI '21}
}

@inproceedings{10.1145/3292500.3330718,
author = {Chakraborty, Prithwish and Farooq, Faisal},
title = {A Robust Framework for Accelerated Outcome-driven Risk Factor Identification from EHR},
year = {2019},
isbn = {9781450362016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3292500.3330718},
doi = {10.1145/3292500.3330718},
abstract = {Electronic Health Records (EHR) containing longitudinal information about millions of patient lives are increasingly being utilized by organizations across the healthcare spectrum. Studies on EHR data have enabled real world applications like understanding of disease progression, outcomes analysis, and comparative effectiveness research. However, often every study is independently commissioned, data is gathered by surveys or specifically purchased per study by a long and often painful process. This is followed by an arduous repetitive cycle of analysis, model building, and generation of insights. This process can take anywhere between 1 - 3 years. In this paper, we present a robust end-to-end machine learning based SaaS system to perform analysis on a very large EHR dataset. The framework consists of a proprietary EHR datamart spanning ~55 million patient lives in USA and over ~20 billion data points. To the best of our knowledge, this framework is the largest in the industry to analyze medical records at this scale, with such efficacy and ease. We developed an end-to-end ML framework with carefully chosen components to support EHR analysis at scale and suitable for further downstream clinical analysis. Specifically, it consists of a ridge regularized Survival Support Vector Machine (SSVM) with a clinical kernel, coupled with Chi-square distance-based feature selection, to uncover relevant risk factors by exploiting the weak correlations in EHR. Our results on multiple real use cases indicate that the framework identifies relevant factors effectively without expert supervision. The framework is stable, generalizable over outcomes, and also found to contribute to better out-of-bound prediction over known expert features. Importantly, the ML methodologies used are interpretable which is critical for acceptance of our system in the targeted user base. With the system being operational, all of these studies were completed within a time frame of 3-4 weeks compared to the industry standard 12-36 months. As such our system can accelerate analysis and discovery, result in better ROI due to reduced investments as well as quicker turn around of studies.},
booktitle = {Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining},
pages = {1800–1808},
numpages = {9},
keywords = {risk analysis, ml in health, health informatics, health ai, electronic health records},
location = {Anchorage, AK, USA},
series = {KDD '19}
}

@inproceedings{10.1145/3459930.3469512,
author = {Gupta, Mehak and Phan, Thao-Ly T. and Bunnell, H. Timothy and Beheshti, Rahmatollah},
title = {Concurrent imputation and prediction on EHR data using bi-directional GANs: Bi-GANs for EHR imputation and prediction},
year = {2021},
isbn = {9781450384506},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3459930.3469512},
doi = {10.1145/3459930.3469512},
abstract = {Working with electronic health records (EHRs) is known to be challenging due to several reasons. These reasons include not having: 1) similar lengths (per visit), 2) the same number of observations (per patient), and 3) complete entries in the available records. These issues hinder the performance of the predictive models created using EHRs. In this paper, we approach these issues by presenting a model for the combined task of imputing and predicting values for the irregularly observed and varying length EHR data with missing entries. Our proposed model (dubbed as Bi-GAN) uses a bidirectional recurrent network in a generative adversarial setting. In this architecture, the generator is a bidirectional recurrent network that receives the EHR data and imputes the existing missing values. The discriminator attempts to discriminate between the actual and the imputed values generated by the generator. Using the input data in its entirety, Bi-GAN learns how to impute missing elements in-between (imputation) or outside of the input time steps (prediction). Our method has three advantages to the state-of-the-art methods in the field: (a) one single model performs both the imputation and prediction tasks; (b) the model can perform predictions using time-series of varying length with missing data; (c) it does not require to know the observation and prediction time window during training and can be used for the predictions with different observation and prediction window lengths, for short- and long-term predictions. We evaluate our model on two large EHR datasets to impute and predict body mass index (BMI) values and show its superior performance in both settings.},
booktitle = {Proceedings of the 12th ACM Conference on Bioinformatics, Computational Biology, and Health Informatics},
articleno = {7},
numpages = {9},
keywords = {recurrent neural network, electronic health record, adversarial training},
location = {Gainesville, Florida},
series = {BCB '21}
}

@inproceedings{10.1145/3543873.3587361,
author = {Choudhury, Sutanay and Agarwal, Khushbu and Ham, Colby and Tamang, Suzanne},
title = {MediSage: An AI Assistant for Healthcare via Composition of Neural-Symbolic Reasoning Operators},
year = {2023},
isbn = {9781450394192},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3543873.3587361},
doi = {10.1145/3543873.3587361},
abstract = {We introduce MediSage, an AI decision support assistant for medical professionals and caregivers that simplifies the way in which they interact with different modalities of electronic health records (EHRs) through a conversational interface. It provides step-by-step reasoning support to an end-user to summarize patient health, predict patient outcomes and provide comprehensive and personalized healthcare recommendations. MediSage provides these reasoning capabilities by using a knowledge graph that combines general purpose clinical knowledge resources with recent-most information from the EHR data. By combining the structured representation of knowledge with the predictive power of neural models trained over both EHR and knowledge graph data, MediSage brings explainability by construction and represents a stepping stone into the future through further integration with biomedical language models.},
booktitle = {Companion Proceedings of the ACM Web Conference 2023},
pages = {258–261},
numpages = {4},
location = {Austin, TX, USA},
series = {WWW '23 Companion}
}

@article{10.1145/2166788.2166789,
author = {Sachdeva, Shelly and Bhalla, Subhash},
title = {Semantic interoperability in standardized electronic health record databases},
year = {2012},
issue_date = {April 2012},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {3},
number = {1},
issn = {1936-1955},
url = {https://doi.org/10.1145/2166788.2166789},
doi = {10.1145/2166788.2166789},
abstract = {Different clinics and hospitals have their own information systems to maintain patient data. This hinders the exchange of data among systems (and organizations). Hence there is a need to provide standards for data exchange. In digitized form, the individual patient's medical record can be stored, retrieved, and shared over a network through enhancement in information technology. Thus, electronic health records (EHRs) should be standardized, incorporating semantic interoperability. A subsequent step requires that healthcare professionals and patients get involved in using the EHRs, with the help of technological developments. This study aims to provide different approaches in understanding some current and challenging concepts in health informatics. Successful handling of these challenges will lead to improved quality in healthcare by reducing medical errors, decreasing costs, and enhancing patient care. The study is focused on the following goals: (1) understanding the role of EHRs; (2) understanding the need for standardization to improve quality; (3) establishing interoperability in maintaining EHRs; (4) examining a framework for standardization and interoperability (the openEHR architecture; (5) identifying the role of archetypes for knowledge-based systems; and (6) understanding the difficulties in querying HER data.},
journal = {J. Data and Information Quality},
month = may,
articleno = {1},
numpages = {37},
keywords = {standardization in EHR, semantic interoperability, quality-based EHR, openEHR, data quality in healthcare, archetype-based EHR, Electronic health records}
}

@inproceedings{10.1145/3459930.3469560,
author = {Tian, Shubo and Erdengasileng, Arslan and Yang, Xi and Guo, Yi and Wu, Yonghui and Zhang, Jinfeng and Bian, Jiang and He, Zhe},
title = {Transformer-based named entity recognition for parsing clinical trial eligibility criteria},
year = {2021},
isbn = {9781450384506},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3459930.3469560},
doi = {10.1145/3459930.3469560},
abstract = {The rapid adoption of electronic health records (EHRs) systems has made clinical data available in electronic format for research and for many downstream applications. Electronic screening of potentially eligible patients using these clinical databases for clinical trials is a critical need to improve trial recruitment efficiency. Nevertheless, manually translating free-text eligibility criteria into database queries is labor intensive and inefficient. To facilitate automated screening, free-text eligibility criteria must be structured and coded into a computable format using controlled vocabularies. Named entity recognition (NER) is thus an important first step. In this study, we evaluate 4 state-of-the-art transformer-based NER models on two publicly available annotated corpora of eligibility criteria released by Columbia University (i.e., the Chia data) and Facebook Research (i.e.the FRD data). Four transformer-based models (i.e., BERT, ALBERT, RoBERTa, and ELECTRA) pretrained with general English domain corpora vs. those pretrained with PubMed citations, clinical notes from the MIMIC-III dataset and eligibility criteria extracted from all the clinical trials on ClinicalTrials.gov were compared. Experimental results show that RoBERTa pretrained with MIMIC-III clinical notes and eligibility criteria yielded the highest strict and relaxed F-scores in both the Chia data (i.e., 0.658/0.798) and the FRD data (i.e., 0.785/0.916). With promising NER results, further investigations on building a reliable natural language processing (NLP)-assisted pipeline for automated electronic screening are needed.},
booktitle = {Proceedings of the 12th ACM Conference on Bioinformatics, Computational Biology, and Health Informatics},
articleno = {49},
numpages = {6},
keywords = {transformer-based model, named entity recognition, eligibility criteria parsing, clinical trial},
location = {Gainesville, Florida},
series = {BCB '21}
}

@inproceedings{10.1145/3626772.3657885,
author = {Xie, Yibo and Wang, Kaifan and Zheng, Jiawei and Liu, Feiyan and Wang, Xiaoli and Huang, Guofeng},
title = {OEHR: An Orthopedic Electronic Health Record Dataset},
year = {2024},
isbn = {9798400704314},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626772.3657885},
doi = {10.1145/3626772.3657885},
abstract = {During the past decades, healthcare institutions continually amassed clinical data that is not intended to support research. Despite the increasing number of publicly available electronic health record (EHR) datasets, it is difficult to find publicly available datasets in Orthopedics that can be used to compare and evaluate downstream tasks. This paper presents OEHR, a healthcare benchmark dataset in Orthopedics, sourced from the EHR of real hospitals. Information available includes patient measurements, diagnoses, treatments, clinical notes, and medical images. OEHR is intended to support clinical research. To evaluate the quality of OEHR, we conduct extensive experiments by implementing state-of-the-art methods for performing downstream tasks. The results show that OEHR serves as a valuable extension to existing publicly available EHR datasets. The dataset is available at http://47.94.174.82/.},
booktitle = {Proceedings of the 47th International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {1126–1135},
numpages = {10},
keywords = {benchmark dataset, electronic health record, orthopedic},
location = {Washington DC, USA},
series = {SIGIR '24}
}

@inproceedings{10.1145/3366423.3380181,
author = {Zhang, Xingyao and Xiao, Cao and Glass, Lucas M. and Sun, Jimeng},
title = {DeepEnroll: Patient-Trial Matching with Deep Embedding and Entailment Prediction},
year = {2020},
isbn = {9781450370233},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3366423.3380181},
doi = {10.1145/3366423.3380181},
abstract = {Clinical trials are essential for drug development but often suffer from expensive, inaccurate and insufficient patient recruitment. The core problem of patient-trial matching is to find qualified patients for a trial, where patient information is stored in electronic health records (EHR) while trial eligibility criteria (EC) are described in text documents available on the web. How to represent longitudinal patient EHR? How to extract complex logical rules from EC? Most existing works rely on manual rule-based extraction, which is time consuming and inflexible for complex inference. To address these challenges, we proposed a cross-modal inference learning model to jointly encode enrollment criteria (text) and patients records (tabular data) into a shared latent space for matching inference. pplies a pre-trained Bidirectional Encoder Representations from Transformers(BERT) model to encode clinical trial information into sentence embedding. And uses a hierarchical embedding model to represent patient longitudinal EHR. In addition, s augmented by a numerical information embedding and entailment module to reason over numerical information in both EC and EHR. These encoders are trained jointly to optimize patient-trial matching score. We evaluated n the trial-patient matching task with demonstrated on real world datasets. utperformed the best baseline by up to 12.4% in average F1.},
booktitle = {Proceedings of The Web Conference 2020},
pages = {1029–1037},
numpages = {9},
keywords = {Trial Recruitment, Machine Learning, Entailment Prediction, Attention Mechanism},
location = {Taipei, Taiwan},
series = {WWW '20}
}

@proceedings{10.1145/3608298,
title = {ICMHI '23: Proceedings of the 2023 7th International Conference on Medical and Health Informatics},
year = {2023},
isbn = {9798400700712},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Kyoto, Japan}
}

@inproceedings{10.1145/2939672.2939715,
author = {Kuang, Zhaobin and Thomson, James and Caldwell, Michael and Peissig, Peggy and Stewart, Ron and Page, David},
title = {Computational Drug Repositioning Using Continuous Self-Controlled Case Series},
year = {2016},
isbn = {9781450342322},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2939672.2939715},
doi = {10.1145/2939672.2939715},
abstract = {Computational Drug Repositioning (CDR) is the task of discovering potential new indications for existing drugs by mining large-scale heterogeneous drug-related data sources. Leveraging the patient-level temporal ordering information between numeric physiological measurements and various drug prescriptions provided in Electronic Health Records (EHRs), we propose a Continuous Self-controlled Case Series (CSCCS) model for CDR. As an initial evaluation, we look for drugs that can control Fasting Blood Glucose (FBG) level in our experiments. Applying CSCCS to the Marshfield Clinic EHR, well-known drugs that are indicated for controlling blood glucose level are rediscovered. Furthermore, some drugs with recent literature support for the potential effect of blood glucose level control are also identified.},
booktitle = {Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
pages = {491–500},
numpages = {10},
keywords = {self-controlled case series, longitudinal data, computational drug repositioning},
location = {San Francisco, California, USA},
series = {KDD '16}
}

@inproceedings{10.1145/3388440.3412460,
author = {Rouzbeh, Fatemeh and Grama, Ananth and Griffin, Paul and Adibuzzaman, Mohammad},
title = {Collaborative Cloud Computing Framework for Health Data with Open Source Technologies},
year = {2020},
isbn = {9781450379649},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3388440.3412460},
doi = {10.1145/3388440.3412460},
abstract = {The proliferation of sensor technologies and advancements in data collection methods have enabled the accumulation of very large amounts of data. Increasingly, these datasets are considered for scientific research. However, the design of the system architecture to achieve high performance in terms of parallelization, query processing time, aggregation of heterogeneous data types (e.g., time series, images, structured data, among others), and difficulty in reproducing scientific research remain a major challenge. This is specifically true for health sciences research, where the systems must be i) easy to use with the flexibility to manipulate data at the most granular level, ii) agnostic of programming language kernel, iii) scalable, and iv) compliant with the HIPAA privacy law. In this paper, we review the existing literature for such big data systems for scientific research in health sciences and identify the gaps of the current system landscape. We propose a novel architecture for software-hardware-data ecosystem using open source technologies such as Apache Hadoop, Kubernetes and JupyterHub in a distributed environment. We also evaluate the system using a large clinical data set of 69M patients.},
booktitle = {Proceedings of the 11th ACM International Conference on Bioinformatics, Computational Biology and Health Informatics},
articleno = {48},
numpages = {10},
keywords = {Kubernetes, JupyterHub, Healthcare, Hadoop, Cloud Computing, Big Data},
location = {Virtual Event, USA},
series = {BCB '20}
}

@article{10.1109/TCBB.2016.2591539,
author = {Moskovitch, Robert and Choi, Hyunmi and Hripcsak, George and Tatonetti, Nicholas},
title = {Prognosis of Clinical Outcomes with Temporal Patterns and Experiences with One Class Feature Selection},
year = {2017},
issue_date = {May 2017},
publisher = {IEEE Computer Society Press},
address = {Washington, DC, USA},
volume = {14},
number = {3},
issn = {1545-5963},
url = {https://doi.org/10.1109/TCBB.2016.2591539},
doi = {10.1109/TCBB.2016.2591539},
abstract = {Accurate prognosis of outcome events, such as clinical procedures or disease diagnosis, is central in medicine. The emergence of longitudinal clinical data, like the Electronic Health Records EHR, represents an opportunity to develop automated methods for predicting patient outcomes. However, these data are highly dimensional and very sparse, complicating the application of predictive modeling techniques. Further, their temporal nature is not fully exploited by current methods, and temporal abstraction was recently used which results in symbolic time intervals representation. We present Maitreya, a framework for the prediction of outcome events that leverages these symbolic time intervals. Using Maitreya, learn predictive models based on the temporal patterns in the clinical records that are prognostic markers and use these markers to train predictive models for eight clinical procedures. In order to decrease the number of patterns that are used as features, we propose the use of three one class feature selection methods. We evaluate the performance of Maitreya under several parameter settings, including the one-class feature selection, and compare our results to that of atemporal approaches. In general, we found that the use of temporal patterns outperformed the atemporal methods, when representing the number of pattern occurrences.},
journal = {IEEE/ACM Trans. Comput. Biol. Bioinformatics},
month = may,
pages = {555–563},
numpages = {9}
}

@inproceedings{10.1145/3535508.3545555,
author = {Zhu, Yuanda and Mahale, Aishwarya and Peters, Kourtney and Mathew, Lejy and Giuste, Felipe and Anderson, Blake and Wang, May D.},
title = {Using natural language processing on free-text clinical notes to identify patients with long-term COVID effects},
year = {2022},
isbn = {9781450393867},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3535508.3545555},
doi = {10.1145/3535508.3545555},
abstract = {As of May 15th, 2022, the novel coronavirus SARS-COV-2 has infected 517 million people and resulted in more than 6.2 million deaths around the world. About 40% to 87% of patients suffer from persistent symptoms weeks or months after their original infection. Despite remarkable progress in preventing and treating acute COVID-19 conditions, the clinical diagnosis of long-term COVID remains difficult. In this work, we use free-text clinical notes and natural language processing (NLP) techniques to explore long-term COVID effects. We first obtain free-text clinical notes from 719 outpatient encounters representing patients treated by physicians at Emory Clinic to detect patterns in patients with long-term COVID symptoms. We apply state-of-the-art NLP frameworks to automatically identify patients with long-term COVID effects, achieving 0.881 recall (sensitivity) score for note-level prediction. We further interpret the prediction outcomes and discuss potential phenotypes. Our work aims to provide a data-driven solution to identify patients who have developed persistent symptoms after acute COVID infection. With this work, clinicians may be able to identify patients who have long-term COVID symptoms to optimize treatment.},
booktitle = {Proceedings of the 13th ACM International Conference on Bioinformatics, Computational Biology and Health Informatics},
articleno = {46},
numpages = {9},
keywords = {natural language processing, long COVID, explainable AI, clinical notes, PASC},
location = {Northbrook, Illinois},
series = {BCB '22}
}

@inproceedings{10.1145/3459930.3469562,
author = {Lyons, Robert and Low, Geoffrey Ross and Congdon, Clare Bates and Ceruolo, Melissa and Ballesteros, Marissa and Cambria, Steven and DePetrillo, Paolo},
title = {Towards an extensible ontology for streaming sensor data for clinical trials},
year = {2021},
isbn = {9781450384506},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3459930.3469562},
doi = {10.1145/3459930.3469562},
abstract = {The use of wearable sensors for clinical trials can lead to better data collection and a better patient experience during trials, and can further allow more patients to participate in trials by allowing more remote monitoring and fewer site visits. However, extracting maximum value from the data collected via streaming sensors presents some specific technical challenges, including processing the data in real time, and storing the sensor data in a representation that facilitates the use of biomarker algorithms that can be used and reused with different similar sensors, at different scales, and across different clinical trials. Here we present our initial work on SORBET, a Sensor Ontology for Reusable Biometric Expressions and Transformations. Our design strategy is presented, along with the initial design and examples. While this ontology has been created for the Medidata Sensor Cloud product, it is our hope that others working in this space will join us in extending and hardening this ontology, as we expand it to incorporate more sensors and more needs for clinical trials research.},
booktitle = {Proceedings of the 12th ACM Conference on Bioinformatics, Computational Biology, and Health Informatics},
articleno = {48},
numpages = {6},
keywords = {semantic networks, ontology engineering, health informatics},
location = {Gainesville, Florida},
series = {BCB '21}
}

@inproceedings{10.1145/3531146.3533166,
author = {Pfohl, Stephen and Xu, Yizhe and Foryciarz, Agata and Ignatiadis, Nikolaos and Genkins, Julian and Shah, Nigam},
title = {Net benefit, calibration, threshold selection, and training objectives for algorithmic fairness in healthcare},
year = {2022},
isbn = {9781450393522},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3531146.3533166},
doi = {10.1145/3531146.3533166},
abstract = {A growing body of work uses the paradigm of algorithmic fairness to frame the development of techniques to anticipate and proactively mitigate the introduction or exacerbation of health inequities that may follow from the use of model-guided decision-making. We evaluate the interplay between measures of model performance, fairness, and the expected utility of decision-making to offer practical recommendations for the operationalization of algorithmic fairness principles for the development and evaluation of predictive models in healthcare. We conduct an empirical case-study via development of models to estimate the ten-year risk of atherosclerotic cardiovascular disease to inform statin initiation in accordance with clinical practice guidelines. We demonstrate that approaches that incorporate fairness considerations into the model training objective typically do not improve model performance or confer greater net benefit for any of the studied patient populations compared to the use of standard learning paradigms followed by threshold selection concordant with patient preferences, evidence of intervention effectiveness, and model calibration. These results hold when the measured outcomes are not subject to differential measurement error across patient populations and threshold selection is unconstrained, regardless of whether differences in model performance metrics, such as in true and false positive error rates, are present. In closing, we argue for focusing model development efforts on developing calibrated models that predict outcomes well for all patient populations while emphasizing that such efforts are complementary to transparent reporting, participatory design, and reasoning about the impact of model-informed interventions in context.},
booktitle = {Proceedings of the 2022 ACM Conference on Fairness, Accountability, and Transparency},
pages = {1039–1052},
numpages = {14},
keywords = {cardiovascular disease, fairness, healthcare},
location = {Seoul, Republic of Korea},
series = {FAccT '22}
}

@inproceedings{10.1145/3437120.3437352,
author = {Markopoulos, Dimitris and Tsolakidis, Anastasios and N. Karanikolas, Nikitas and Skourlas, Christos},
title = {Towards the design of a Conceptual Framework for the operation of Intensive Care Units based on Big Data Analysis},
year = {2021},
isbn = {9781450388979},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3437120.3437352},
doi = {10.1145/3437120.3437352},
abstract = {The development of Big Data Analytics (BDA) technology and the maturity of the Machine Learning (ML) sector offer great opportunities for applications in Intensive Care Units (ICUs). This paper describes a Conceptual Framework and proposes its use in designing architectures and big data applications in ICUs. The Conceptual Framework is based on BDA,MLNatural Language Processing (NLP) and consists of the following subsystems: The "Big Data Integration and ICUs" module, the "ICUs and critical care services" module, the "Use of standards and ICUs" module, the "Machine Learning and ICUs" module, and the “NLP and ICUs” module. The framework is developed using Soft System Methodology (SSM) and Design Science Research Methodology (DSRM).},
booktitle = {Proceedings of the 24th Pan-Hellenic Conference on Informatics},
pages = {411–415},
numpages = {5},
keywords = {Machine Learning, Intensive Care Unit, Conceptual Framework, Big Data Analysis},
location = {Athens, Greece},
series = {PCI '20}
}

@inproceedings{10.1145/1183568.1183577,
author = {Bhatti, Rafae and Moidu, Khalid and Ghafoor, Arif},
title = {Policy-based security management for federated healthcare databases (or RHIOs)},
year = {2006},
isbn = {1595935282},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1183568.1183577},
doi = {10.1145/1183568.1183577},
abstract = {The role of security management in the RHIOs has recently gained increasing attention due to strict privacy and disclosure rules, and federal regulations such as HIPAA. The envisioned use of electronic health care records in such systems involves pervasive and ubiquitous access to healthcare information from anywhere outside of traditional hospital boundaries which puts increasing demands on the underlying security mechanisms. In this paper, we have designed a context-aware policy-based system to provide security management for health informatics. The policies are based on a set of use cases developed for the HL7 Clinical Document Architecture (CDA) standard. Our system is designed to adapt well to ubiquitous healthcare services in a non-traditional, pervasive environment using the same infrastructure that enables federated healthcare management for traditional organizational boundaries. We also present an enforcement architecture and a demonstration prototype for the policy-based system proposed in this paper.},
booktitle = {Proceedings of the International Workshop on Healthcare Information and Knowledge Management},
pages = {41–48},
numpages = {8},
keywords = {role based access control, privacy and disclosure policy, federated healthcare architecture},
location = {Arlington, Virginia, USA},
series = {HIKM '06}
}

@inproceedings{10.1145/2063576.2064006,
author = {Roitman, Haggai and Yogev, Sivan and Tsimerman, Yevgenia and Kim, Dae Won and Mesika, Yossi},
title = {Exploratory search over social-medical data},
year = {2011},
isbn = {9781450307178},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2063576.2064006},
doi = {10.1145/2063576.2064006},
abstract = {In this demo we shall present the IBM Patient Empowerment System (PES), and more specifically, its social-medical discovery sub-system. Social and medical data are represented using entities and relationships and are explored using a combination of expressive, yet intuitive, query language, faceted search, and ER graph navigation. While this demonstration focuses on the healthcare domain, the underlining search technology is generic and can be utilized in many other domains. Therefore, this demo has two main contributions. First, we present a novel entity-relationship indexing and retrieval solution, and discuss its implementation challenges. Second, the demonstration depicts a practical entity-relationship discovery technology in a real domain setting within a real IBM system.},
booktitle = {Proceedings of the 20th ACM International Conference on Information and Knowledge Management},
pages = {2513–2516},
numpages = {4},
keywords = {social-medical discovery, exploratory search, entity-relationship data, IBM patient empowerment system},
location = {Glasgow, Scotland, UK},
series = {CIKM '11}
}

@inproceedings{10.1145/1987993.1988005,
author = {Mouttham, Alain and Peyton, Liam and Kuziemsky, Craig},
title = {Leveraging performance analytics to improve integration of care},
year = {2011},
isbn = {9781450305853},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1987993.1988005},
doi = {10.1145/1987993.1988005},
abstract = {The need for healthcare systems to provide efficient, effective and integrated care has put an emphasis on performance analytics. However while performance analytics can measure outcomes and suggest policy and protocol for achieving efficiency; it does not drive the actual integration of care processes. There is a need for research that develops fine-grained metrics and illustrates how to link them into the underlying clinical care processes in order to drive and support integration of care. An integrated case study of cardiac care processes and performance analytics we have been developing at a community hospital in Ontario is used to illustrate our approach. We analyze how fine-grained metrics can be linked into cardiac care processes to address high level performance objectives, and present a technology assessment to identify how software engineering support for the collection and communication of these fine-grained metrics can be provided.},
booktitle = {Proceedings of the 3rd Workshop on Software Engineering in Health Care},
pages = {56–62},
numpages = {7},
keywords = {performance analytics, metrics, integrated care, information technology},
location = {Waikiki, Honolulu, HI, USA},
series = {SEHC '11}
}

@article{10.1145/257874.257898,
author = {Kilman, David G. and Forslund, David W.},
title = {An international collaboratory based on virtual patient records},
year = {1997},
issue_date = {Aug. 1997},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {40},
number = {8},
issn = {0001-0782},
url = {https://doi.org/10.1145/257874.257898},
doi = {10.1145/257874.257898},
journal = {Commun. ACM},
month = aug,
pages = {110–117},
numpages = {8}
}

@inproceedings{10.5555/3492252.3492269,
author = {Zhang, Peng and Schmidt, Douglas C. and White, Jules},
title = {A pattern sequence for designing blockchain-based healthcare information technology systems},
year = {2021},
publisher = {The Hillside Group},
address = {USA},
abstract = {Known for its decentralized and tamper-aware properties, blockchain is attractive to enhance the infrastructure of systems that have been constrained by traditionally centralized and vendor-locked environments. Although blockchain has commonly been used as the operational model behind cryptocurrency, it has far more foreseeable utilities in domains like healthcare, where efficient data flow is highly demanded. Particularly, blockchain and related technologies have been touted as foundational technologies for addressing healthcare interoperability challenges, such as promoting effective communications and securing data exchanges across various healthcare systems. Despite the increasing interests in leveraging blockchain technology to improve healthcare infrastructures, a major gap in literature is the lack of available recommendations for concrete architectural styles and design considerations for creating blockchain-based apps and systems with a healthcare focus.This research provides two contributions to bridge the gap in existing research. First, we introduce a pattern sequence for designing blockchain-based healthcare systems focused on secure and at-scale data exchange. Our approach adapts traditional software patterns and proposes novel patterns that take into account both the technical requirements specific to healthcare systems and the implications of these requirements on naive blockchain-based solutions. Second, we provide a pattern-oriented reference architecture using an example application of the pattern sequence for guiding software developers to design interoperable (on the technical level) healthcare IT systems atop blockchain-based infrastructures. The reference architecture focuses on minimizing storage requirements on-chain, preserving the privacy of sensitive information, facilitating scalable communications, and maximizing evolvability of the system.},
booktitle = {Proceedings of the 26th Conference on Pattern Languages of Programs},
articleno = {14},
numpages = {22},
keywords = {solidity, software engineering, smart contracts, smart contract security and vulnerability, interoperability, healthcare, design patterns, data sharing, blockchain technology},
location = {Urbana, Illinois},
series = {PLoP '19}
}

@proceedings{10.1145/3555776,
title = {SAC '23: Proceedings of the 38th ACM/SIGAPP Symposium on Applied Computing},
year = {2023},
isbn = {9781450395175},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Tallinn, Estonia}
}

@proceedings{10.1145/3600211,
title = {AIES '23: Proceedings of the 2023 AAAI/ACM Conference on AI, Ethics, and Society},
year = {2023},
isbn = {9798400702310},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Montr\'{e}al, QC, Canada}
}

@proceedings{10.1145/3598469,
title = {dg.o '23: Proceedings of the 24th Annual International Conference on Digital Government Research},
year = {2023},
isbn = {9798400708374},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Gda?sk, Poland}
}

@proceedings{10.1145/3575882,
title = {IC3INA '22: Proceedings of the 2022 International Conference on Computer, Control, Informatics and Its Applications},
year = {2022},
isbn = {9781450397902},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Virtual Event, Indonesia}
}

@proceedings{10.1145/3587828,
title = {ICSCA '23: Proceedings of the 2023 12th International Conference on Software and Computer Applications},
year = {2023},
isbn = {9781450398589},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Kuantan, Malaysia}
}

@proceedings{10.1145/3613904,
title = {CHI '24: Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Honolulu, HI, USA}
}

@proceedings{10.1145/3626772,
title = {SIGIR '24: Proceedings of the 47th International ACM SIGIR Conference on Research and Development in Information Retrieval},
year = {2024},
isbn = {9798400704314},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {Welcome to the 47th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR 2024), taking place in Washington D.C., USA, from July 14 to 18, 2024.SIGIR serves as the foremost international forum for the presentation of groundbreaking research findings, the demonstration of innovative systems and techniques, and the exploration of forwardthinking research directions in the field of information retrieval.This year's SIGIR is an in-person conference. We believe that an in-person conference is beneficial for several reasons: it fosters direct engagement and networking opportunities, enhances the exchange of research ideas, contributes to a more dynamic and productive conference experience, and nurtures our research community by welcoming newcomers, providing them with the opportunity to become acquainted with SIGIR traditions. This decision has not been made lightly. We understand the challenges that can pose in the aftermath of a pandemic and amidst the uncertainties of the world around us. To accommodate those who cannot attend, we have implemented a series of measures such as proxy presenters, livestreaming, and recording sessions. These steps are taken to ensure that everyone has access to the valuable content that the conference offers.},
location = {Washington DC, USA}
}

@proceedings{10.1145/3544548,
title = {CHI '23: Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Hamburg, Germany}
}

@proceedings{10.1145/3673277,
title = {CNSCT '24: Proceedings of the 2024 3rd International Conference on Cryptography, Network Security and Communication Technology},
year = {2024},
isbn = {9798400716959},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Harbin, China}
}

@proceedings{10.1145/3308558,
title = {WWW '19: The World Wide Web Conference},
year = {2019},
isbn = {9781450366748},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {It is our great pleasure to welcome you to The Web Conference 2019. The Web Conference is the premier venue focused on understanding the current state and the evolution of the Web through the lens of computer science, computational social science, economics, policy, and many other disciplines. The 2019 edition of the conference is a reflection point as we celebrate the 30th anniversary of the Web.},
location = {San Francisco, CA, USA}
}

@proceedings{10.1109/3656336,
title = {ASPDAC '22: Proceedings of the 27th Asia and South Pacific Design Automation Conference},
year = {2022},
isbn = {9781665421355},
publisher = {IEEE Press},
abstract = {ASP-DAC is a high-quality and premium conference on Electronic Design Automation (EDA) like other sister conferences such as Design Automation Conference (DAC), Design, Automation &amp; Test in Europe (DATE), International Conference on Computer Aided Design (ICCAD), and Embedded Systems Week (ESWEEK). ASP-DAC started in 1995 and has continuously offered opportunities for researchers and designers in the world to learn about the advancements on design and automation of electronic systems.},
location = {Taipei, Taiwan}
}

@proceedings{10.1145/3664476,
title = {ARES '24: Proceedings of the 19th International Conference on Availability, Reliability and Security},
year = {2024},
isbn = {9798400717185},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Vienna, Austria}
}

@proceedings{10.1145/3575693,
title = {ASPLOS 2023: Proceedings of the 28th ACM International Conference on Architectural Support for Programming Languages and Operating Systems, Volume 2},
year = {2023},
isbn = {9781450399166},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {It is our pleasure to introduce Volume II of ASPLOS ’23. For the first time, ASPLOS has embarked on a new multi-deadline review model. ASPLOS ’23 features 3 deadlines spaced throughout the year and papers will be published in three volumes. Multiple deadlines are meant to encourage authors to submit their papers when ready and to facilitate the selection of some papers for revision. For this volume of ASPLOS ’23, we discontinued the use of the 2-page extended abstract submissions that were used in ASPLOS ’21 and ASPLOS ’22. We found the extended abstract offered limited filtering and moved to a more traditional two phase review process. Each paper received 3 reviews in phase 1 and papers with positive scores advanced to the second round and received up to 2 more reviews. In our preface to Volume III, we will give a more detailed rundown of how the process worked.},
location = {Vancouver, BC, Canada}
}

